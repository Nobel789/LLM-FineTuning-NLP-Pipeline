{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Patient Triage: Urgent vs. Non-Urgent Case Classification with PEFT\n",
    "\n",
    "**Features:**\n",
    "- Synthetic dataset for urgent/non-urgent free-text symptoms\n",
    "- BlueBERT (or ClinicalBERT) + LoRA parameter-efficient fine-tuning\n",
    "- Training, evaluation (accuracy, precision, recall, F1)\n",
    "- Inference example\n",
    "- (Bonus) API deployment guidance"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Install dependencies\n",
    "!pip install transformers datasets peft scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Synthetic Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "urgent_symptoms = [\n",
    "    \"sudden severe chest pain and shortness of breath\",\n",
    "    \"loss of consciousness and slurred speech\",\n",
    "    \"massive bleeding from a wound\",\n",
    "    \"severe abdominal pain with vomiting blood\",\n",
    "    \"high fever with neck stiffness\",\n",
    "    \"new onset seizure\",\n",
    "    \"severe allergic reaction and swelling of lips\",\n",
    "    \"acute confusion and inability to move arm or leg\"\n",
    "]\n",
    "\n",
    "nonurgent_symptoms = [\n",
    "    \"mild headache for two days, no other symptoms\",\n",
    "    \"intermittent knee pain when walking\",\n",
    "    \"itchy skin with mild redness\",\n",
    "    \"occasional cough without fever\",\n",
    "    \"runny nose and mild sore throat\",\n",
    "    \"feeling tired after work\",\n",
    "    \"low back pain for one week after lifting box\",\n",
    "    \"seasonal allergies causing sneezing\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "for _ in range(120):\n",
    "    if random.random() < 0.5:\n",
    "        symptom = random.choice(urgent_symptoms)\n",
    "        label = 1  # urgent\n",
    "    else:\n",
    "        symptom = random.choice(nonurgent_symptoms)\n",
    "        label = 0  # non-urgent\n",
    "    data.append({\"symptom\": symptom, \"label\": label})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df.to_csv(\"synthetic_triage_data.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. LoRA (PEFT) Fine-Tuning with BlueBERT/ClinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Choose model: BlueBERT or ClinicalBERT\n",
    "# model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "model_name = \"bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Data\n",
    "df = pd.read_csv(\"synthetic_triage_data.csv\")\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.rename_column(\"symptom\", \"text\")\n",
    "dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1, bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "def preprocess(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "\n",
    "tokenized_ds = dataset.map(preprocess, batched=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./triage_bluebert_lora\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_f1\"\n",
    ")\n",
    "\n",
    "# Custom metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "def compute_metrics(pred):\n",
    "    preds = pred.predictions.argmax(axis=1)\n",
    "    labels = pred.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=None, labels=[0,1])\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_nonurgent\": p[0],\n",
    "        \"recall_nonurgent\": r[0],\n",
    "        \"f1_nonurgent\": f1[0],\n",
    "        \"precision_urgent\": p[1],\n",
    "        \"recall_urgent\": r[1],\n",
    "        \"f1_urgent\": f1[1],\n",
    "        \"eval_f1\": f1.mean()\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"./triage_bluebert_lora\")\n",
    "tokenizer.save_pretrained(\"./triage_bluebert_lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Evaluation: See metrics in logs and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate on test set\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = tokenized_ds[\"test\"][\"labels\"]\n",
    "y_pred = trainer.predict(tokenized_ds[\"test\"]).predictions.argmax(axis=1)\n",
    "print(classification_report(y_true, y_pred, target_names=[\"non-urgent\", \"urgent\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./triage_bluebert_lora\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./triage_bluebert_lora\")\n",
    "\n",
    "def triage_predict(symptom_text):\n",
    "    inputs = tokenizer(symptom_text, return_tensors=\"pt\", truncation=True, max_length=64)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        pred = logits.argmax(dim=1).item()\n",
    "        return \"Urgent\" if pred == 1 else \"Non-Urgent\"\n",
    "\n",
    "# Example inference\n",
    "test_symptoms = [\n",
    "    \"acute confusion and inability to move arm or leg\",\n",
    "    \"runny nose and mild sore throat\"\n",
    "]\n",
    "for text in test_symptoms:\n",
    "    print(f'Symptom: {text}\\nPredicted triage: {triage_predict(text)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. (Bonus) API Deployment Guidance\n",
    "- Export model and tokenizer as above\n",
    "- Use [FastAPI](https://fastapi.tiangolo.com/) or [Flask](https://flask.palletsprojects.com/) for a REST API:\n",
    "    - Load model at startup\n",
    "    - Accept POST requests with a symptom text\n",
    "    - Return the triage prediction\n",
    "- Example FastAPI endpoint:\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "app = FastAPI()\n",
    "\n",
    "class Input(BaseModel):\n",
    "    symptom: str\n",
    "\n",
    "@app.post(\"/triage\")\n",
    "def triage(input: Input):\n",
    "    pred = triage_predict(input.symptom)\n",
    "    return {\"triage\": pred}\n",
    "```\n",
    "- Deploy on [Hugging Face Spaces](https://huggingface.co/spaces), [AWS Lambda](https://aws.amazon.com/lambda/), or your own server."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}